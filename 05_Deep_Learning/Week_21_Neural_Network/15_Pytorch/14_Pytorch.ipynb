{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g2YVw5xRevsN"
   },
   "source": [
    "# <font color = 'orange'> Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDHdsQOQj7kV"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5klIS0iugLU_"
   },
   "source": [
    "## Tensors\n",
    "\n",
    "At its core, PyTorch is a library for processing tensors. A tensor is a number, vector, matrix, or any n-dimensional array. Let's create a tensor with a single number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SuXLgoHqetTc"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1699865041516,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "U2szt52xhOkd",
    "outputId": "18d7643f-20a2-4970-9576-0ea9325df970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# creating a scaler in torch\n",
    "t1 = torch.tensor(4.)\n",
    "print(t1)\n",
    "print(t1.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1699865041516,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "5rcV7y0OhVc0",
    "outputId": "725f19f4-2363-4ba6-d139-d4a1a8ab95b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# creating an array in torch\n",
    "t2 = torch.tensor([1,2,3,4])\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1699865041516,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "JQs2yISfhtaY",
    "outputId": "7ad1c1fa-8c9f-41cc-90f5-31911174e9d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5,  6],\n",
      "        [ 7,  8],\n",
      "        [ 9, 10]])\n"
     ]
    }
   ],
   "source": [
    "# creating a 2D tensor in torch\n",
    "t3 = torch.tensor([ [5, 6], [7, 8], [9, 10] ])\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1699865041516,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "KwH90Dpih6VM",
    "outputId": "12e7c0ef-44b7-4086-f16d-68bd74e3dc57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[11, 12, 13],\n",
      "         [14, 15, 16]],\n",
      "\n",
      "        [[17, 18, 19],\n",
      "         [20, 21, 22]]])\n"
     ]
    }
   ],
   "source": [
    "# creating 3D tensor in torch\n",
    "t4 = torch.tensor([\n",
    "    [\n",
    "        [11, 12, 13],\n",
    "        [14, 15, 16]\n",
    "    ],\n",
    "    [\n",
    "        [17, 18, 19],\n",
    "        [20, 21, 22]\n",
    "    ]\n",
    " ])\n",
    "\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1699865041516,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "vrYywEdQiYq7",
    "outputId": "749c0f82-7965-4b12-e09c-448a7162ddcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n",
      "torch.Size([]) \n",
      "\n",
      "tensor([1, 2, 3, 4])\n",
      "torch.Size([4]) \n",
      "\n",
      "tensor([[ 5,  6],\n",
      "        [ 7,  8],\n",
      "        [ 9, 10]])\n",
      "torch.Size([3, 2]) \n",
      "\n",
      "tensor([[[11, 12, 13],\n",
      "         [14, 15, 16]],\n",
      "\n",
      "        [[17, 18, 19],\n",
      "         [20, 21, 22]]])\n",
      "torch.Size([2, 2, 3]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# to find the shape of the tensor\n",
    "\n",
    "print(t1)\n",
    "print(t1.shape,'\\n')\n",
    "\n",
    "print(t2)\n",
    "print(t2.shape,'\\n')\n",
    "\n",
    "print(t3)\n",
    "print(t3.shape, '\\n')\n",
    "\n",
    "print(t4)\n",
    "print(t4.shape, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "error",
     "timestamp": 1699865041516,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "2iW_9ljMisi9",
    "outputId": "3faebd4f-2265-4fff-ea8a-4e52d519b193"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 3 at dim 1 (got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_35824\\4214416924.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# we cannot create a ragged array in torch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mt5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: expected sequence of length 3 at dim 1 (got 2)"
     ]
    }
   ],
   "source": [
    "# we cannot create a ragged array in torch\n",
    "\n",
    "t5 = torch.tensor([[1, 2, 3],[4, 5],[6]])\n",
    "print(t5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RhtGBLfcj478"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRrVsca-kBXM"
   },
   "source": [
    "## Tensor operations and gradients\n",
    "\n",
    "We can combine tensors with the usual arithmetic operations.  \n",
    "Let's look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1699865050712,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "tXF6Ve4sj15h",
    "outputId": "4ede56b7-2dc1-435f-a1f0-9c8c8b67bbc7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3.), tensor(4., requires_grad=True), tensor(5., requires_grad=True))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensors.\n",
    "x = torch.tensor(3.)\n",
    "w = torch.tensor(4., requires_grad=True) # we can differentiate the variable w.r.t to another variable\n",
    "b = torch.tensor(5., requires_grad=True)\n",
    "x, w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-hmlDDkkO7V"
   },
   "source": [
    "We've created three tensors: `x`, `w`, and `b`, all numbers. `w` and `b` have an additional parameter `requires_grad` set to `True`. We'll see what it does in just a moment.\n",
    "\n",
    "Let's create a new tensor `y` by combining these tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1699865051372,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "B3Ghr9TtkOrH",
    "outputId": "68e72ff6-8e74-4028-80be-609b649bd478"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arithmetic operations\n",
    "y = w * x + b\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "x9TQ6qYDkOkd"
   },
   "outputs": [],
   "source": [
    "# compute derivates\n",
    "# y.backward() tells that we have to differentiate y w.r.t to all the possible variable where requires_grad = True\n",
    "y.backward() # backward comes from backward propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1699865051811,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "_6ExuHFakOdm",
    "outputId": "dccbeeb4-f79b-417a-efc8-fc00195fe62f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx : None\n",
      "dy/dw : tensor(3.)\n",
      "dy/db : tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# display gradients\n",
    "print('dy/dx :',x.grad) #  requires_grad = False\n",
    "print('dy/dw :',w.grad)\n",
    "print('dy/db :',b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGpoMh-7mjqF"
   },
   "source": [
    "As expected, `dy/dw` has the same value as `x`, i.e., `3`, and `dy/db` has the value `1`. Note that `x.grad` is `None` because `x` doesn't have `requires_grad` set to `True`.\n",
    "\n",
    "The \"grad\" in `w.grad` is short for _gradient_, which is another term for derivative. The term _gradient_ is primarily used while dealing with vectors and matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PuXYZXemqdM"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onMXy1wnmntt"
   },
   "source": [
    "## Tensor functions\n",
    "\n",
    "Apart from arithmetic operations, the `torch` module also contains many functions for creating and manipulating tensors. Let's look at some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1699865054211,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "uFvthuN6kOUF",
    "outputId": "e265c00a-d275-47c9-e067-721e289e8605"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[42, 42],\n",
       "        [42, 42],\n",
       "        [42, 42]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor with a fixed value for every element\n",
    "t6 = torch.full((3, 2), 42)\n",
    "t6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1699865054211,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "vWZ0JPxhmpys",
    "outputId": "125edde3-7007-4ef5-c671-87a935958411"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5,  6],\n",
      "        [ 7,  8],\n",
      "        [ 9, 10]]) \n",
      "\n",
      "tensor([[42, 42],\n",
      "        [42, 42],\n",
      "        [42, 42]]) \n",
      "\n",
      "Concatination \n",
      " tensor([[ 5,  6],\n",
      "        [ 7,  8],\n",
      "        [ 9, 10],\n",
      "        [42, 42],\n",
      "        [42, 42],\n",
      "        [42, 42]])\n"
     ]
    }
   ],
   "source": [
    "t7 = torch.cat((t3, t6))\n",
    "\n",
    "print(t3, '\\n')\n",
    "print(t6, '\\n')\n",
    "\n",
    "print('Concatination \\n',t7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1699865054850,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "rIYVgJZxnYNo",
    "outputId": "a475af44-ad8f-49ab-e6a3-c375f93ebec2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9589, -0.2794],\n",
       "        [ 0.6570,  0.9894],\n",
       "        [ 0.4121, -0.5440],\n",
       "        [-0.9165, -0.9165],\n",
       "        [-0.9165, -0.9165],\n",
       "        [-0.9165, -0.9165]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t8 = torch.sin(t7)\n",
    "\n",
    "t8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1699865054851,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "nZjGcmH3ntQc",
    "outputId": "809d13d6-e4ff-46f6-9973-1acf946190bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9589, -0.2794],\n",
       "         [ 0.6570,  0.9894]],\n",
       "\n",
       "        [[ 0.4121, -0.5440],\n",
       "         [-0.9165, -0.9165]],\n",
       "\n",
       "        [[-0.9165, -0.9165],\n",
       "         [-0.9165, -0.9165]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t9 = t8.reshape(3, 2, 2)\n",
    "\n",
    "t9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZIvCDJIoGiU"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFX-HcsgoH4U"
   },
   "source": [
    "## Interoperability with Numpy\n",
    "\n",
    "[Numpy](http://www.numpy.org/) is a popular open-source library used for mathematical and scientific computing in Python. It enables efficient operations on large multi-dimensional arrays and has a vast ecosystem of supporting libraries, including:\n",
    "\n",
    "* [Pandas](https://pandas.pydata.org/) for file I/O and data analysis\n",
    "* [Matplotlib](https://matplotlib.org/) for plotting and visualization\n",
    "* [OpenCV](https://opencv.org/) for image and video processing\n",
    "\n",
    "\n",
    "Instead of reinventing the wheel, PyTorch interoperates well with Numpy to leverage its existing ecosystem of tools and libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1699865056265,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "qiopPzPEn0IW",
    "outputId": "34acff9f-2f14-49ca-fe66-d02231434e9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([[1, 2], [3, 4]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1699865056941,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "uMuHQ_QcplXV",
    "outputId": "a7588d0b-e07e-4ff5-c3b5-0d0c7af2a674"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]], dtype=torch.int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting numpy array to a torch tensor\n",
    "y = torch.from_numpy(x)\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1699865056941,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "QvczpOiWp62y",
    "outputId": "e72f50b1-05c9-4867-8108-a6455114bfdc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting torch tensor to a numpy arrary\n",
    "z = y.numpy()\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXUR3RTpqME-"
   },
   "source": [
    "The interoperability between PyTorch and Numpy is essential because most datasets you'll work with will likely be read and preprocessed as Numpy arrays.\n",
    "\n",
    "You might wonder why we need a library like PyTorch at all since Numpy already provides data structures and utilities for working with multi-dimensional numeric data. There are two main reasons:\n",
    "\n",
    "1. **Autograd**: The ability to automatically compute gradients for tensor operations is essential for training deep learning models.\n",
    "2. **GPU support**: While working with massive datasets and large models, PyTorch tensor operations can be performed efficiently using a Graphics Processing Unit (GPU). Computations that might typically take hours can be completed within minutes using GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Me8wmX_-qNoh"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xzPQR56qTDm"
   },
   "source": [
    "## Linear Regression using pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H84dgrBjw_QS"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "oNwi6ZqzqGpT"
   },
   "outputs": [],
   "source": [
    "#making training data\n",
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43],\n",
    "                   [91, 88, 64],\n",
    "                   [87, 134, 58],\n",
    "                   [102, 43, 37],\n",
    "                   [69, 96, 70]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "c-olMnM_qctK"
   },
   "outputs": [],
   "source": [
    "# Targets (apples, oranges)\n",
    "# we have to output to predict\n",
    "target = np.array([[56, 70],\n",
    "                    [81, 101],\n",
    "                    [119, 133],\n",
    "                    [22, 37],\n",
    "                    [103, 119]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1699865059861,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "PlptkgOPqeML",
    "outputId": "37ebe99b-16bd-435e-dee4-829d0d8a1ebe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]]) \n",
      "\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "# converting inputs and target which are in numpy array to a torch tensor\n",
    "inputs = torch.from_numpy(inputs)\n",
    "target = torch.from_numpy(target)\n",
    "\n",
    "print(inputs, '\\n')\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPmNoARHxAQ4"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1699865061184,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "ugeoIPmUrL00",
    "outputId": "10355884-b5f6-4baa-92c3-600ccd085532"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3462,  0.0238,  1.0212],\n",
      "        [-1.9029,  0.5728, -0.9464]], requires_grad=True) \n",
      "\n",
      "tensor([-0.2942,  0.3121], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# weights and baises\n",
    "\n",
    "# 3 weights for each output as there are 3 input features\n",
    "w = torch.randn(2, 3, requires_grad = True)\n",
    "# 1 bias for each output\n",
    "b = torch.randn(2, requires_grad = True)\n",
    "\n",
    "print(w, '\\n')\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCr0KLk1xAr8"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "zpKBCcxAsE91"
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "# best fit line formula for multiple linear regression(i.e more than 1 output class)\n",
    "# y = w.Transpose() * x + b\n",
    "\n",
    "def model(x):\n",
    "    return x @ w.t() + b\n",
    "\n",
    "# shape of the variables\n",
    "# x = 5x3\n",
    "# w = 2x3\n",
    "# b = 1x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mL7m51GFxA-v"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1699865063660,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "uY9OYNTTsxSz",
    "outputId": "7480bc3f-2ca9-43ea-f7f7-4da5ef56d441"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  19.9360, -140.9179],\n",
       "        [  35.6483, -183.0155],\n",
       "        [  31.9985, -143.3764],\n",
       "        [   3.1990, -204.1723],\n",
       "        [  49.5818, -142.2466]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction\n",
    "pred = model(inputs)\n",
    "# output orange and apple for 5 inputs\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1699865064243,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "Wc_h9ouLuJnq",
    "outputId": "1f8b5159-eab4-4b89-c93b-4a1b524aff57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "# actual output\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNYuzPSDxBSh"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Tv8Yhy1yuYtG"
   },
   "outputs": [],
   "source": [
    "# loss function MSE\n",
    "\n",
    "def MSE(actual, predicted):\n",
    "    diff = actual - predicted\n",
    "    return torch.sum(diff * diff) / diff.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1699865066666,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "tR8gkt7gvOsC",
    "outputId": "8aa9bd86-11a6-4d8d-c7e4-f7896ce2aaf3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(34208.2578, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# error\n",
    "loss = MSE(target, pred)\n",
    "loss\n",
    "# as weights and bais are randomly initialized our loss will be high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6no5OGzxC0q"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "7sh-d3EjvstG"
   },
   "outputs": [],
   "source": [
    "# compute gradients\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1699865070243,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "sCNooQ0sv9_G",
    "outputId": "22d398e9-325f-452f-ee12-b1bbdcf53efc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3462,  0.0238,  1.0212],\n",
      "        [-1.9029,  0.5728, -0.9464]], requires_grad=True) \n",
      "\n",
      "tensor([[ -3986.4746,  -4800.4077,  -2786.8525],\n",
      "        [-21582.5508, -22321.8770, -14097.3867]])\n"
     ]
    }
   ],
   "source": [
    "print(w, '\\n')\n",
    "# w.grad(gradient descent) gives the (gives slope at particular point)differenitation of loss w.r.t weights\n",
    "print(w.grad) # dL/dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1699865070678,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "gfoRIcr_wCK3",
    "outputId": "1a362440-663f-4fd7-c9eb-8bba81ccac48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2942,  0.3121], requires_grad=True) \n",
      "\n",
      "tensor([ -48.1273, -254.7457])\n"
     ]
    }
   ],
   "source": [
    "print(b, '\\n')\n",
    "print(b.grad) # dL/dB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdOKC8SJxJDR"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 589,
     "status": "ok",
     "timestamp": 1699865073258,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "U_ag-f9BwzI0",
    "outputId": "ea97f5f2-b146-47b8-e022-0ecb97186d84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# reset gradient\n",
    "w.grad.zero_()\n",
    "b.grad.zero_()\n",
    "\n",
    "# after every epoch we reset the gradient otherwise it will keep on accumulating\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1699865074497,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "a4hsYre6xeVP",
    "outputId": "fb00acbc-9b1c-4894-b27e-36e7337986c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 400 and loss 45.273277282714844\n",
      "Epoch 2 / 400 and loss 45.1656379699707\n",
      "Epoch 3 / 400 and loss 45.05843734741211\n",
      "Epoch 4 / 400 and loss 44.951759338378906\n",
      "Epoch 5 / 400 and loss 44.84560775756836\n",
      "Epoch 6 / 400 and loss 44.73998260498047\n",
      "Epoch 7 / 400 and loss 44.634727478027344\n",
      "Epoch 8 / 400 and loss 44.530052185058594\n",
      "Epoch 9 / 400 and loss 44.42581558227539\n",
      "Epoch 10 / 400 and loss 44.32209777832031\n",
      "Epoch 11 / 400 and loss 44.21875762939453\n",
      "Epoch 12 / 400 and loss 44.11594772338867\n",
      "Epoch 13 / 400 and loss 44.013572692871094\n",
      "Epoch 14 / 400 and loss 43.91169738769531\n",
      "Epoch 15 / 400 and loss 43.81022644042969\n",
      "Epoch 16 / 400 and loss 43.7092399597168\n",
      "Epoch 17 / 400 and loss 43.608673095703125\n",
      "Epoch 18 / 400 and loss 43.508541107177734\n",
      "Epoch 19 / 400 and loss 43.4088134765625\n",
      "Epoch 20 / 400 and loss 43.309627532958984\n",
      "Epoch 21 / 400 and loss 43.21076202392578\n",
      "Epoch 22 / 400 and loss 43.11243438720703\n",
      "Epoch 23 / 400 and loss 43.01438903808594\n",
      "Epoch 24 / 400 and loss 42.916847229003906\n",
      "Epoch 25 / 400 and loss 42.81966018676758\n",
      "Epoch 26 / 400 and loss 42.72296905517578\n",
      "Epoch 27 / 400 and loss 42.62659454345703\n",
      "Epoch 28 / 400 and loss 42.53062438964844\n",
      "Epoch 29 / 400 and loss 42.43511199951172\n",
      "Epoch 30 / 400 and loss 42.33997344970703\n",
      "Epoch 31 / 400 and loss 42.24523162841797\n",
      "Epoch 32 / 400 and loss 42.150856018066406\n",
      "Epoch 33 / 400 and loss 42.056922912597656\n",
      "Epoch 34 / 400 and loss 41.963294982910156\n",
      "Epoch 35 / 400 and loss 41.87000274658203\n",
      "Epoch 36 / 400 and loss 41.77725601196289\n",
      "Epoch 37 / 400 and loss 41.68474578857422\n",
      "Epoch 38 / 400 and loss 41.59260177612305\n",
      "Epoch 39 / 400 and loss 41.50093460083008\n",
      "Epoch 40 / 400 and loss 41.40947341918945\n",
      "Epoch 41 / 400 and loss 41.318458557128906\n",
      "Epoch 42 / 400 and loss 41.227813720703125\n",
      "Epoch 43 / 400 and loss 41.13752365112305\n",
      "Epoch 44 / 400 and loss 41.047489166259766\n",
      "Epoch 45 / 400 and loss 40.957923889160156\n",
      "Epoch 46 / 400 and loss 40.868629455566406\n",
      "Epoch 47 / 400 and loss 40.77968215942383\n",
      "Epoch 48 / 400 and loss 40.69114685058594\n",
      "Epoch 49 / 400 and loss 40.60286331176758\n",
      "Epoch 50 / 400 and loss 40.514862060546875\n",
      "Epoch 51 / 400 and loss 40.42734146118164\n",
      "Epoch 52 / 400 and loss 40.340049743652344\n",
      "Epoch 53 / 400 and loss 40.253108978271484\n",
      "Epoch 54 / 400 and loss 40.16649627685547\n",
      "Epoch 55 / 400 and loss 40.08017349243164\n",
      "Epoch 56 / 400 and loss 39.99419403076172\n",
      "Epoch 57 / 400 and loss 39.908546447753906\n",
      "Epoch 58 / 400 and loss 39.82313919067383\n",
      "Epoch 59 / 400 and loss 39.73810958862305\n",
      "Epoch 60 / 400 and loss 39.653358459472656\n",
      "Epoch 61 / 400 and loss 39.56891632080078\n",
      "Epoch 62 / 400 and loss 39.48479461669922\n",
      "Epoch 63 / 400 and loss 39.400901794433594\n",
      "Epoch 64 / 400 and loss 39.31743240356445\n",
      "Epoch 65 / 400 and loss 39.23414993286133\n",
      "Epoch 66 / 400 and loss 39.15115737915039\n",
      "Epoch 67 / 400 and loss 39.068504333496094\n",
      "Epoch 68 / 400 and loss 38.98615264892578\n",
      "Epoch 69 / 400 and loss 38.904056549072266\n",
      "Epoch 70 / 400 and loss 38.822227478027344\n",
      "Epoch 71 / 400 and loss 38.740665435791016\n",
      "Epoch 72 / 400 and loss 38.659446716308594\n",
      "Epoch 73 / 400 and loss 38.578468322753906\n",
      "Epoch 74 / 400 and loss 38.49774932861328\n",
      "Epoch 75 / 400 and loss 38.41731262207031\n",
      "Epoch 76 / 400 and loss 38.3371467590332\n",
      "Epoch 77 / 400 and loss 38.25730895996094\n",
      "Epoch 78 / 400 and loss 38.17768096923828\n",
      "Epoch 79 / 400 and loss 38.09829330444336\n",
      "Epoch 80 / 400 and loss 38.01924133300781\n",
      "Epoch 81 / 400 and loss 37.94038009643555\n",
      "Epoch 82 / 400 and loss 37.861812591552734\n",
      "Epoch 83 / 400 and loss 37.78352355957031\n",
      "Epoch 84 / 400 and loss 37.70549011230469\n",
      "Epoch 85 / 400 and loss 37.627601623535156\n",
      "Epoch 86 / 400 and loss 37.550052642822266\n",
      "Epoch 87 / 400 and loss 37.47279357910156\n",
      "Epoch 88 / 400 and loss 37.395687103271484\n",
      "Epoch 89 / 400 and loss 37.31891632080078\n",
      "Epoch 90 / 400 and loss 37.24229049682617\n",
      "Epoch 91 / 400 and loss 37.16599655151367\n",
      "Epoch 92 / 400 and loss 37.08990478515625\n",
      "Epoch 93 / 400 and loss 37.014068603515625\n",
      "Epoch 94 / 400 and loss 36.93850326538086\n",
      "Epoch 95 / 400 and loss 36.86309814453125\n",
      "Epoch 96 / 400 and loss 36.78795623779297\n",
      "Epoch 97 / 400 and loss 36.713016510009766\n",
      "Epoch 98 / 400 and loss 36.638343811035156\n",
      "Epoch 99 / 400 and loss 36.563926696777344\n",
      "Epoch 100 / 400 and loss 36.48969650268555\n",
      "Epoch 101 / 400 and loss 36.41569519042969\n",
      "Epoch 102 / 400 and loss 36.341949462890625\n",
      "Epoch 103 / 400 and loss 36.26839065551758\n",
      "Epoch 104 / 400 and loss 36.195064544677734\n",
      "Epoch 105 / 400 and loss 36.12203598022461\n",
      "Epoch 106 / 400 and loss 36.049095153808594\n",
      "Epoch 107 / 400 and loss 35.97644805908203\n",
      "Epoch 108 / 400 and loss 35.90399932861328\n",
      "Epoch 109 / 400 and loss 35.83171844482422\n",
      "Epoch 110 / 400 and loss 35.759761810302734\n",
      "Epoch 111 / 400 and loss 35.68787384033203\n",
      "Epoch 112 / 400 and loss 35.61634063720703\n",
      "Epoch 113 / 400 and loss 35.5449104309082\n",
      "Epoch 114 / 400 and loss 35.47373580932617\n",
      "Epoch 115 / 400 and loss 35.402732849121094\n",
      "Epoch 116 / 400 and loss 35.332008361816406\n",
      "Epoch 117 / 400 and loss 35.261451721191406\n",
      "Epoch 118 / 400 and loss 35.191070556640625\n",
      "Epoch 119 / 400 and loss 35.12092590332031\n",
      "Epoch 120 / 400 and loss 35.05091094970703\n",
      "Epoch 121 / 400 and loss 34.981178283691406\n",
      "Epoch 122 / 400 and loss 34.91161346435547\n",
      "Epoch 123 / 400 and loss 34.84227752685547\n",
      "Epoch 124 / 400 and loss 34.773014068603516\n",
      "Epoch 125 / 400 and loss 34.704078674316406\n",
      "Epoch 126 / 400 and loss 34.635276794433594\n",
      "Epoch 127 / 400 and loss 34.56668472290039\n",
      "Epoch 128 / 400 and loss 34.49829864501953\n",
      "Epoch 129 / 400 and loss 34.430049896240234\n",
      "Epoch 130 / 400 and loss 34.36195755004883\n",
      "Epoch 131 / 400 and loss 34.294166564941406\n",
      "Epoch 132 / 400 and loss 34.22651290893555\n",
      "Epoch 133 / 400 and loss 34.15900421142578\n",
      "Epoch 134 / 400 and loss 34.09171676635742\n",
      "Epoch 135 / 400 and loss 34.024627685546875\n",
      "Epoch 136 / 400 and loss 33.95768737792969\n",
      "Epoch 137 / 400 and loss 33.89092254638672\n",
      "Epoch 138 / 400 and loss 33.824398040771484\n",
      "Epoch 139 / 400 and loss 33.757965087890625\n",
      "Epoch 140 / 400 and loss 33.691802978515625\n",
      "Epoch 141 / 400 and loss 33.625732421875\n",
      "Epoch 142 / 400 and loss 33.55988693237305\n",
      "Epoch 143 / 400 and loss 33.49423599243164\n",
      "Epoch 144 / 400 and loss 33.428688049316406\n",
      "Epoch 145 / 400 and loss 33.36335372924805\n",
      "Epoch 146 / 400 and loss 33.29820251464844\n",
      "Epoch 147 / 400 and loss 33.233158111572266\n",
      "Epoch 148 / 400 and loss 33.16837692260742\n",
      "Epoch 149 / 400 and loss 33.103675842285156\n",
      "Epoch 150 / 400 and loss 33.03921890258789\n",
      "Epoch 151 / 400 and loss 32.974876403808594\n",
      "Epoch 152 / 400 and loss 32.91071319580078\n",
      "Epoch 153 / 400 and loss 32.84672927856445\n",
      "Epoch 154 / 400 and loss 32.78292465209961\n",
      "Epoch 155 / 400 and loss 32.719261169433594\n",
      "Epoch 156 / 400 and loss 32.65573501586914\n",
      "Epoch 157 / 400 and loss 32.59239196777344\n",
      "Epoch 158 / 400 and loss 32.52915573120117\n",
      "Epoch 159 / 400 and loss 32.466224670410156\n",
      "Epoch 160 / 400 and loss 32.40335464477539\n",
      "Epoch 161 / 400 and loss 32.340633392333984\n",
      "Epoch 162 / 400 and loss 32.2780647277832\n",
      "Epoch 163 / 400 and loss 32.2156867980957\n",
      "Epoch 164 / 400 and loss 32.153472900390625\n",
      "Epoch 165 / 400 and loss 32.0914192199707\n",
      "Epoch 166 / 400 and loss 32.02943801879883\n",
      "Epoch 167 / 400 and loss 31.96769142150879\n",
      "Epoch 168 / 400 and loss 31.906078338623047\n",
      "Epoch 169 / 400 and loss 31.844600677490234\n",
      "Epoch 170 / 400 and loss 31.783254623413086\n",
      "Epoch 171 / 400 and loss 31.72212791442871\n",
      "Epoch 172 / 400 and loss 31.661144256591797\n",
      "Epoch 173 / 400 and loss 31.6002254486084\n",
      "Epoch 174 / 400 and loss 31.539480209350586\n",
      "Epoch 175 / 400 and loss 31.478973388671875\n",
      "Epoch 176 / 400 and loss 31.418527603149414\n",
      "Epoch 177 / 400 and loss 31.3582706451416\n",
      "Epoch 178 / 400 and loss 31.298107147216797\n",
      "Epoch 179 / 400 and loss 31.23809242248535\n",
      "Epoch 180 / 400 and loss 31.17828941345215\n",
      "Epoch 181 / 400 and loss 31.118560791015625\n",
      "Epoch 182 / 400 and loss 31.059036254882812\n",
      "Epoch 183 / 400 and loss 30.999584197998047\n",
      "Epoch 184 / 400 and loss 30.940359115600586\n",
      "Epoch 185 / 400 and loss 30.881235122680664\n",
      "Epoch 186 / 400 and loss 30.822223663330078\n",
      "Epoch 187 / 400 and loss 30.763355255126953\n",
      "Epoch 188 / 400 and loss 30.704660415649414\n",
      "Epoch 189 / 400 and loss 30.64609718322754\n",
      "Epoch 190 / 400 and loss 30.587636947631836\n",
      "Epoch 191 / 400 and loss 30.52932357788086\n",
      "Epoch 192 / 400 and loss 30.47117042541504\n",
      "Epoch 193 / 400 and loss 30.41318130493164\n",
      "Epoch 194 / 400 and loss 30.355228424072266\n",
      "Epoch 195 / 400 and loss 30.297515869140625\n",
      "Epoch 196 / 400 and loss 30.2398681640625\n",
      "Epoch 197 / 400 and loss 30.182397842407227\n",
      "Epoch 198 / 400 and loss 30.125011444091797\n",
      "Epoch 199 / 400 and loss 30.067819595336914\n",
      "Epoch 200 / 400 and loss 30.01070213317871\n",
      "Epoch 201 / 400 and loss 29.95371437072754\n",
      "Epoch 202 / 400 and loss 29.896921157836914\n",
      "Epoch 203 / 400 and loss 29.8402156829834\n",
      "Epoch 204 / 400 and loss 29.783618927001953\n",
      "Epoch 205 / 400 and loss 29.727153778076172\n",
      "Epoch 206 / 400 and loss 29.67087745666504\n",
      "Epoch 207 / 400 and loss 29.61464500427246\n",
      "Epoch 208 / 400 and loss 29.5585994720459\n",
      "Epoch 209 / 400 and loss 29.50271224975586\n",
      "Epoch 210 / 400 and loss 29.446868896484375\n",
      "Epoch 211 / 400 and loss 29.39121437072754\n",
      "Epoch 212 / 400 and loss 29.335620880126953\n",
      "Epoch 213 / 400 and loss 29.28025245666504\n",
      "Epoch 214 / 400 and loss 29.224899291992188\n",
      "Epoch 215 / 400 and loss 29.169734954833984\n",
      "Epoch 216 / 400 and loss 29.114700317382812\n",
      "Epoch 217 / 400 and loss 29.059772491455078\n",
      "Epoch 218 / 400 and loss 29.004924774169922\n",
      "Epoch 219 / 400 and loss 28.950210571289062\n",
      "Epoch 220 / 400 and loss 28.895706176757812\n",
      "Epoch 221 / 400 and loss 28.84122085571289\n",
      "Epoch 222 / 400 and loss 28.786880493164062\n",
      "Epoch 223 / 400 and loss 28.732666015625\n",
      "Epoch 224 / 400 and loss 28.67856788635254\n",
      "Epoch 225 / 400 and loss 28.624588012695312\n",
      "Epoch 226 / 400 and loss 28.570758819580078\n",
      "Epoch 227 / 400 and loss 28.51700782775879\n",
      "Epoch 228 / 400 and loss 28.463388442993164\n",
      "Epoch 229 / 400 and loss 28.40988540649414\n",
      "Epoch 230 / 400 and loss 28.356531143188477\n",
      "Epoch 231 / 400 and loss 28.303253173828125\n",
      "Epoch 232 / 400 and loss 28.250106811523438\n",
      "Epoch 233 / 400 and loss 28.197046279907227\n",
      "Epoch 234 / 400 and loss 28.1441593170166\n",
      "Epoch 235 / 400 and loss 28.091358184814453\n",
      "Epoch 236 / 400 and loss 28.03862953186035\n",
      "Epoch 237 / 400 and loss 27.986114501953125\n",
      "Epoch 238 / 400 and loss 27.933603286743164\n",
      "Epoch 239 / 400 and loss 27.881267547607422\n",
      "Epoch 240 / 400 and loss 27.829025268554688\n",
      "Epoch 241 / 400 and loss 27.776906967163086\n",
      "Epoch 242 / 400 and loss 27.72488021850586\n",
      "Epoch 243 / 400 and loss 27.672954559326172\n",
      "Epoch 244 / 400 and loss 27.621196746826172\n",
      "Epoch 245 / 400 and loss 27.569549560546875\n",
      "Epoch 246 / 400 and loss 27.5179500579834\n",
      "Epoch 247 / 400 and loss 27.46651268005371\n",
      "Epoch 248 / 400 and loss 27.415142059326172\n",
      "Epoch 249 / 400 and loss 27.36393165588379\n",
      "Epoch 250 / 400 and loss 27.312774658203125\n",
      "Epoch 251 / 400 and loss 27.261754989624023\n",
      "Epoch 252 / 400 and loss 27.21088218688965\n",
      "Epoch 253 / 400 and loss 27.160015106201172\n",
      "Epoch 254 / 400 and loss 27.109384536743164\n",
      "Epoch 255 / 400 and loss 27.058740615844727\n",
      "Epoch 256 / 400 and loss 27.008270263671875\n",
      "Epoch 257 / 400 and loss 26.95792579650879\n",
      "Epoch 258 / 400 and loss 26.907604217529297\n",
      "Epoch 259 / 400 and loss 26.857446670532227\n",
      "Epoch 260 / 400 and loss 26.807388305664062\n",
      "Epoch 261 / 400 and loss 26.757450103759766\n",
      "Epoch 262 / 400 and loss 26.70758628845215\n",
      "Epoch 263 / 400 and loss 26.657821655273438\n",
      "Epoch 264 / 400 and loss 26.608184814453125\n",
      "Epoch 265 / 400 and loss 26.558609008789062\n",
      "Epoch 266 / 400 and loss 26.509180068969727\n",
      "Epoch 267 / 400 and loss 26.459869384765625\n",
      "Epoch 268 / 400 and loss 26.410634994506836\n",
      "Epoch 269 / 400 and loss 26.361515045166016\n",
      "Epoch 270 / 400 and loss 26.312488555908203\n",
      "Epoch 271 / 400 and loss 26.263525009155273\n",
      "Epoch 272 / 400 and loss 26.214725494384766\n",
      "Epoch 273 / 400 and loss 26.165964126586914\n",
      "Epoch 274 / 400 and loss 26.11736488342285\n",
      "Epoch 275 / 400 and loss 26.068857192993164\n",
      "Epoch 276 / 400 and loss 26.02042579650879\n",
      "Epoch 277 / 400 and loss 25.972131729125977\n",
      "Epoch 278 / 400 and loss 25.923852920532227\n",
      "Epoch 279 / 400 and loss 25.8757381439209\n",
      "Epoch 280 / 400 and loss 25.8277530670166\n",
      "Epoch 281 / 400 and loss 25.779804229736328\n",
      "Epoch 282 / 400 and loss 25.7319393157959\n",
      "Epoch 283 / 400 and loss 25.68424415588379\n",
      "Epoch 284 / 400 and loss 25.63656997680664\n",
      "Epoch 285 / 400 and loss 25.5891170501709\n",
      "Epoch 286 / 400 and loss 25.5416316986084\n",
      "Epoch 287 / 400 and loss 25.494291305541992\n",
      "Epoch 288 / 400 and loss 25.447031021118164\n",
      "Epoch 289 / 400 and loss 25.399871826171875\n",
      "Epoch 290 / 400 and loss 25.352855682373047\n",
      "Epoch 291 / 400 and loss 25.30589485168457\n",
      "Epoch 292 / 400 and loss 25.25899887084961\n",
      "Epoch 293 / 400 and loss 25.21222686767578\n",
      "Epoch 294 / 400 and loss 25.16556167602539\n",
      "Epoch 295 / 400 and loss 25.11899757385254\n",
      "Epoch 296 / 400 and loss 25.07251739501953\n",
      "Epoch 297 / 400 and loss 25.026123046875\n",
      "Epoch 298 / 400 and loss 24.97983741760254\n",
      "Epoch 299 / 400 and loss 24.933616638183594\n",
      "Epoch 300 / 400 and loss 24.88748550415039\n",
      "Epoch 301 / 400 and loss 24.841514587402344\n",
      "Epoch 302 / 400 and loss 24.795576095581055\n",
      "Epoch 303 / 400 and loss 24.74972915649414\n",
      "Epoch 304 / 400 and loss 24.704004287719727\n",
      "Epoch 305 / 400 and loss 24.6583251953125\n",
      "Epoch 306 / 400 and loss 24.612781524658203\n",
      "Epoch 307 / 400 and loss 24.567365646362305\n",
      "Epoch 308 / 400 and loss 24.521940231323242\n",
      "Epoch 309 / 400 and loss 24.47666358947754\n",
      "Epoch 310 / 400 and loss 24.431514739990234\n",
      "Epoch 311 / 400 and loss 24.38638687133789\n",
      "Epoch 312 / 400 and loss 24.341371536254883\n",
      "Epoch 313 / 400 and loss 24.296466827392578\n",
      "Epoch 314 / 400 and loss 24.251628875732422\n",
      "Epoch 315 / 400 and loss 24.206890106201172\n",
      "Epoch 316 / 400 and loss 24.16218376159668\n",
      "Epoch 317 / 400 and loss 24.117643356323242\n",
      "Epoch 318 / 400 and loss 24.07318687438965\n",
      "Epoch 319 / 400 and loss 24.02880096435547\n",
      "Epoch 320 / 400 and loss 23.984495162963867\n",
      "Epoch 321 / 400 and loss 23.940282821655273\n",
      "Epoch 322 / 400 and loss 23.896160125732422\n",
      "Epoch 323 / 400 and loss 23.85213279724121\n",
      "Epoch 324 / 400 and loss 23.808177947998047\n",
      "Epoch 325 / 400 and loss 23.764318466186523\n",
      "Epoch 326 / 400 and loss 23.720548629760742\n",
      "Epoch 327 / 400 and loss 23.676868438720703\n",
      "Epoch 328 / 400 and loss 23.633228302001953\n",
      "Epoch 329 / 400 and loss 23.589746475219727\n",
      "Epoch 330 / 400 and loss 23.546316146850586\n",
      "Epoch 331 / 400 and loss 23.502986907958984\n",
      "Epoch 332 / 400 and loss 23.4597110748291\n",
      "Epoch 333 / 400 and loss 23.41654396057129\n",
      "Epoch 334 / 400 and loss 23.3734188079834\n",
      "Epoch 335 / 400 and loss 23.330472946166992\n",
      "Epoch 336 / 400 and loss 23.287532806396484\n",
      "Epoch 337 / 400 and loss 23.244701385498047\n",
      "Epoch 338 / 400 and loss 23.201955795288086\n",
      "Epoch 339 / 400 and loss 23.159273147583008\n",
      "Epoch 340 / 400 and loss 23.116703033447266\n",
      "Epoch 341 / 400 and loss 23.074222564697266\n",
      "Epoch 342 / 400 and loss 23.031810760498047\n",
      "Epoch 343 / 400 and loss 22.989456176757812\n",
      "Epoch 344 / 400 and loss 22.947221755981445\n",
      "Epoch 345 / 400 and loss 22.905046463012695\n",
      "Epoch 346 / 400 and loss 22.862960815429688\n",
      "Epoch 347 / 400 and loss 22.82100486755371\n",
      "Epoch 348 / 400 and loss 22.779043197631836\n",
      "Epoch 349 / 400 and loss 22.73721694946289\n",
      "Epoch 350 / 400 and loss 22.695472717285156\n",
      "Epoch 351 / 400 and loss 22.653757095336914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 352 / 400 and loss 22.612197875976562\n",
      "Epoch 353 / 400 and loss 22.57071304321289\n",
      "Epoch 354 / 400 and loss 22.52927017211914\n",
      "Epoch 355 / 400 and loss 22.487890243530273\n",
      "Epoch 356 / 400 and loss 22.446653366088867\n",
      "Epoch 357 / 400 and loss 22.405479431152344\n",
      "Epoch 358 / 400 and loss 22.364376068115234\n",
      "Epoch 359 / 400 and loss 22.323314666748047\n",
      "Epoch 360 / 400 and loss 22.282373428344727\n",
      "Epoch 361 / 400 and loss 22.241512298583984\n",
      "Epoch 362 / 400 and loss 22.200754165649414\n",
      "Epoch 363 / 400 and loss 22.160032272338867\n",
      "Epoch 364 / 400 and loss 22.11937713623047\n",
      "Epoch 365 / 400 and loss 22.078868865966797\n",
      "Epoch 366 / 400 and loss 22.038389205932617\n",
      "Epoch 367 / 400 and loss 21.997961044311523\n",
      "Epoch 368 / 400 and loss 21.957674026489258\n",
      "Epoch 369 / 400 and loss 21.917396545410156\n",
      "Epoch 370 / 400 and loss 21.87723159790039\n",
      "Epoch 371 / 400 and loss 21.837207794189453\n",
      "Epoch 372 / 400 and loss 21.797197341918945\n",
      "Epoch 373 / 400 and loss 21.75723648071289\n",
      "Epoch 374 / 400 and loss 21.717418670654297\n",
      "Epoch 375 / 400 and loss 21.677631378173828\n",
      "Epoch 376 / 400 and loss 21.637937545776367\n",
      "Epoch 377 / 400 and loss 21.59835433959961\n",
      "Epoch 378 / 400 and loss 21.55877113342285\n",
      "Epoch 379 / 400 and loss 21.519323348999023\n",
      "Epoch 380 / 400 and loss 21.479923248291016\n",
      "Epoch 381 / 400 and loss 21.440570831298828\n",
      "Epoch 382 / 400 and loss 21.401357650756836\n",
      "Epoch 383 / 400 and loss 21.362201690673828\n",
      "Epoch 384 / 400 and loss 21.323123931884766\n",
      "Epoch 385 / 400 and loss 21.28414535522461\n",
      "Epoch 386 / 400 and loss 21.245189666748047\n",
      "Epoch 387 / 400 and loss 21.20632553100586\n",
      "Epoch 388 / 400 and loss 21.167509078979492\n",
      "Epoch 389 / 400 and loss 21.128816604614258\n",
      "Epoch 390 / 400 and loss 21.09019660949707\n",
      "Epoch 391 / 400 and loss 21.05162811279297\n",
      "Epoch 392 / 400 and loss 21.013137817382812\n",
      "Epoch 393 / 400 and loss 20.974712371826172\n",
      "Epoch 394 / 400 and loss 20.936376571655273\n",
      "Epoch 395 / 400 and loss 20.89809799194336\n",
      "Epoch 396 / 400 and loss 20.859928131103516\n",
      "Epoch 397 / 400 and loss 20.821779251098633\n",
      "Epoch 398 / 400 and loss 20.78375816345215\n",
      "Epoch 399 / 400 and loss 20.745777130126953\n",
      "Epoch 400 / 400 and loss 20.707849502563477\n"
     ]
    }
   ],
   "source": [
    "# Training for multiple epochs\n",
    "for i in range(400):\n",
    "    preds = model(inputs)\n",
    "    loss = MSE(target, preds)\n",
    "    loss.backward() # to calculate the gradient of 6 weights and 2 bias\n",
    "\n",
    "    with torch.no_grad():\n",
    "        lr =  1e-5 # learning rate\n",
    "        # change weights and bais using w = w - (alpha * dL/dw) to reduce loss\n",
    "        w -= w.grad * lr\n",
    "        b -= b.grad * lr\n",
    "        # reset the gradient\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "\n",
    "    print(f'Epoch {i+1} / 400 and loss {loss}')\n",
    "\n",
    "# our loss will get reduced for every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1699865191956,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "dFQsclTlySim",
    "outputId": "e7de19a3-4a03-4e02-9d74-161c7737fd4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20.6700, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# prediction with new model\n",
    "\n",
    "preds = model(inputs)\n",
    "loss = MSE(target, preds)\n",
    "print(loss)\n",
    "# our loss is reduced from 22129.2246 to 133.5157"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGPbFp3e3glt"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1699865349327,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "7uc9aDEW3F-R",
    "outputId": "2dfc3b9c-9934-4b38-d9d5-74773796904a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Values \n",
      " tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]]) \n",
      "\n",
      "\n",
      "Predicted Values \n",
      " tensor([[ 56.9172,  70.8043],\n",
      "        [ 84.1505,  96.5361],\n",
      "        [114.6704, 141.5655],\n",
      "        [ 20.1411,  39.1192],\n",
      "        [105.7920, 110.7839]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('Actual Values \\n', target,'\\n\\n')\n",
    "print('Predicted Values \\n',preds)\n",
    "# our prediction are some what closer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5MJVz7F3tn7"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYoSjay_4CnZ"
   },
   "source": [
    "## Neural Network using Pytorch\n",
    "Dataset used is the Fashion MNIST dataset which is present in the `torch vision` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "dWMLsRv47m-J"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn # neural network\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets # dataset is present in torchvision module\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6694,
     "status": "ok",
     "timestamp": 1699866886146,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "1JOnNomk8m2r",
    "outputId": "17b6e448-874a-450a-f481-0e90c31e0ffe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 26421880/26421880 [00:10<00:00, 2454193.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 29515/29515 [00:00<00:00, 144954.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 4422102/4422102 [00:02<00:00, 1950706.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5148/5148 [00:00<00:00, 2620103.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# downloading training data\n",
    "training_data = datasets.FashionMNIST(root = 'data', train = True, download = True, transform = ToTensor())\n",
    "\n",
    "# downloading test data\n",
    "test_data = datasets.FashionMNIST(root = 'data', train = False, download = True, transform = ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1699867042694,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "u5xlaO409iB3",
    "outputId": "511f3895-1c85-4809-8247-ad1d57fc7839"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.FashionMNIST"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 444,
     "status": "ok",
     "timestamp": 1699867395055,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "R0c40KMC-KBt",
    "outputId": "e37b14e1-bf27-4f9b-82f0-621648dd7953"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
      "Shape of y:  torch.Size([64]) torch.int64\n",
      "\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 7, 3, 4, 1, 2, 4, 8, 0, 2, 5, 7, 9,\n",
      "        1, 4, 6, 0, 9, 3, 8, 8, 3, 3, 8, 0, 7, 5, 7, 9, 6, 1, 3, 7, 6, 7, 2, 1,\n",
      "        2, 2, 4, 4, 5, 8, 2, 2, 8, 4, 8, 0, 7, 7, 8, 5])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# creating data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "# for everytime we call test_dataloader it will give us the 64 records\n",
    "for x, y in test_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", x.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    print()\n",
    "    print(x)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 446,
     "status": "ok",
     "timestamp": 1699867545476,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "6CocIhlI_GRs",
    "outputId": "0a944721-fcab-4d06-bfaf-ecec1faeccb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 426,
     "status": "ok",
     "timestamp": 1699868369539,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "lrA2s9R3AEsU",
    "outputId": "99a5492b-8cfa-4c79-a734-76764e9928b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): Softmax(dim=None)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        # input_layer = 28*28, hidden_layer1 = 512, hidden_layer2 = 512, output_layer = 10\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(28*28, 512), # connect from 28*28 neuron layer to 512 neuron layer\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, 10),\n",
    "                nn.Softmax()\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input is x we have to flatten the image\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "bcXgHaoTC0o1"
   },
   "outputs": [],
   "source": [
    "# loss calculation\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 871,
     "status": "ok",
     "timestamp": 1699869610121,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "KwHEJiCADtPK"
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train() # telling model that it is training model\n",
    "    # ex: batch normalization layer behaves different during train and evaluation time\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # predict and calculate the error\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # back propogation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(x)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1699870144573,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "bRdp2fAcH8ZG"
   },
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 74066,
     "status": "ok",
     "timestamp": 1699870220400,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "H_QZGHloJtJ0",
    "outputId": "e606d021-b527-48ad-dca5-3635e0851c72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.301853  [    0/60000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darsh\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.301404  [ 6400/60000]\n",
      "loss: 2.301467  [12800/60000]\n",
      "loss: 2.302562  [19200/60000]\n",
      "loss: 2.300681  [25600/60000]\n",
      "loss: 2.301144  [32000/60000]\n",
      "loss: 2.301294  [38400/60000]\n",
      "loss: 2.300223  [44800/60000]\n",
      "loss: 2.301973  [51200/60000]\n",
      "loss: 2.301639  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 17.4%, Avg loss: 2.300764 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.300459  [    0/60000]\n",
      "loss: 2.300156  [ 6400/60000]\n",
      "loss: 2.299892  [12800/60000]\n",
      "loss: 2.301411  [19200/60000]\n",
      "loss: 2.299201  [25600/60000]\n",
      "loss: 2.299381  [32000/60000]\n",
      "loss: 2.300031  [38400/60000]\n",
      "loss: 2.298625  [44800/60000]\n",
      "loss: 2.300725  [51200/60000]\n",
      "loss: 2.300221  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 19.1%, Avg loss: 2.299264 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.299032  [    0/60000]\n",
      "loss: 2.298865  [ 6400/60000]\n",
      "loss: 2.298250  [12800/60000]\n",
      "loss: 2.300213  [19200/60000]\n",
      "loss: 2.297649  [25600/60000]\n",
      "loss: 2.297542  [32000/60000]\n",
      "loss: 2.298701  [38400/60000]\n",
      "loss: 2.296918  [44800/60000]\n",
      "loss: 2.299428  [51200/60000]\n",
      "loss: 2.298705  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 19.9%, Avg loss: 2.297673 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.297524  [    0/60000]\n",
      "loss: 2.297482  [ 6400/60000]\n",
      "loss: 2.296500  [12800/60000]\n",
      "loss: 2.298930  [19200/60000]\n",
      "loss: 2.295981  [25600/60000]\n",
      "loss: 2.295574  [32000/60000]\n",
      "loss: 2.297261  [38400/60000]\n",
      "loss: 2.295058  [44800/60000]\n",
      "loss: 2.298028  [51200/60000]\n",
      "loss: 2.297061  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 20.7%, Avg loss: 2.295945 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.295900  [    0/60000]\n",
      "loss: 2.295971  [ 6400/60000]\n",
      "loss: 2.294602  [12800/60000]\n",
      "loss: 2.297535  [19200/60000]\n",
      "loss: 2.294147  [25600/60000]\n",
      "loss: 2.293413  [32000/60000]\n",
      "loss: 2.295666  [38400/60000]\n",
      "loss: 2.292992  [44800/60000]\n",
      "loss: 2.296495  [51200/60000]\n",
      "loss: 2.295247  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 22.2%, Avg loss: 2.294038 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 521,
     "status": "ok",
     "timestamp": 1699870226986,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "WqmElv8aJvx1",
    "outputId": "425a9a27-7bec-4aa9-cd81-141853a7e293"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "#save model\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1699870231118,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "gAGLJw_UKTOO",
    "outputId": "1018052a-27f7-4d40-aaf3-192c4f8cc3d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load model\n",
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1699870239892,
     "user": {
      "displayName": "DARSHAN R M",
      "userId": "08374798748719570782"
     },
     "user_tz": -330
    },
    "id": "3WPM8fQbKUTR",
    "outputId": "ec582d69-5610-4505-b0f5-a1d2c6f50450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nHDkKhdKaPg"
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM1YswNJ8oO7zKXLd+H21i3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
