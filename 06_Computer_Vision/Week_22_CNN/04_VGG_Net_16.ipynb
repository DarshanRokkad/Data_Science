{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "785a2fe3",
   "metadata": {},
   "source": [
    "# <font color = 'orange'> VGG16 Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510cd364",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45864e5a",
   "metadata": {},
   "source": [
    "### <font color='blue'> Downloading zip file from the google drive.\n",
    "* zip file contains the cat and dog folder which contains respective images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da4c9025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12jiQxJzYSYl3wnC8x5wHAhRzzJmmsCXP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?/export=download&id=12jiQxJzYSYl3wnC8x5wHAhRzzJmmsCXP\n",
      "To: E:\\PW Skills - Data Science\\06_Computer_Vision\\Week_22_CNN\\catdog.zip\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 9.09M/9.09M [00:03<00:00, 2.72MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'catdog.zip'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "url = \"https://drive.google.com/file/d/12jiQxJzYSYl3wnC8x5wHAhRzzJmmsCXP/view?usp=sharing\"\n",
    "file_id = url.split(\"/\")[-2] # we want this id '12jiQxJzYSYl3wnC8x5wHAhRzzJmmsCXP' from url\n",
    "print(file_id)\n",
    "\n",
    "prefix = 'https://drive.google.com/uc?/export=download&id='\n",
    "gdown.download(prefix+file_id, \"catdog.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ab9f53",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810dc9f4",
   "metadata": {},
   "source": [
    "### <font color='blue'> Unzipping the downloaded zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c98758f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip catdog.zip -> not working \n",
    "\n",
    "# solution\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('catdog.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('catdog')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4da7356",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879d12a6",
   "metadata": {},
   "source": [
    "### <font color='blue'> Loading data and Image generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "095469a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 337 images belonging to 2 classes.\n",
      "Found 59 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# locating directory\n",
    "train_data_dir = 'catdog/train'\n",
    "validation_data_dir = 'catdog/validation'\n",
    "\n",
    "# setting samples\n",
    "num_train_samples = 2000\n",
    "num_validation_samples = 800\n",
    "\n",
    "# setting epochs and batch size \n",
    "Epochs = 5\n",
    "Batch_size = 16\n",
    "\n",
    "# Image augmentation\n",
    "# preprocessing - to convert all images into 224 x 224 which is accepted by the VGG16 Net\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function = tf.keras.applications.vgg16.preprocess_input)\n",
    "validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function = tf.keras.applications.vgg16.preprocess_input)\n",
    "\n",
    "# intiating the generators using data generator for training and validation \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size = (224, 224),\n",
    "    batch_size = Batch_size,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size = (224, 224),\n",
    "    batch_size = Batch_size,\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5deec9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793359dd",
   "metadata": {},
   "source": [
    "### <font color='blue'> Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d1db39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 15s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               6422784   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21137729 (80.63 MB)\n",
      "Trainable params: 6423041 (24.50 MB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# we don't want last layers as our output conatins different number of classes\n",
    "base_model = tf.keras.applications.vgg16.VGG16(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\n",
    "\n",
    "# as vgg16 is trained on large data and assigned weights to filters so we don't want to retrain those layer so we will freeze them\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False       #vgg16 parameters are made untrainable by freezing there parameters\n",
    "    \n",
    "    \n",
    "\n",
    "# create the model \n",
    "model = tf.keras.models.Sequential()\n",
    "# add base model layers\n",
    "model.add(base_model)\n",
    "# add custom layers\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5)) # regularization - to reduce overfitting\n",
    "model.add(tf.keras.layers.Dense(1, activation = 'sigmoid')) # 1 neuron in output layer as our out is binary i.e cat or dog \n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675f5dd2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfda9e8",
   "metadata": {},
   "source": [
    "### <font color='blue'> Model Compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5673c77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam()\n",
    "\n",
    "model.compile(\n",
    "    loss = 'binary_crossentropy',\n",
    "    optimizer = adam ,\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2f49a6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43907d8",
   "metadata": {},
   "source": [
    "### <font color='blue'> Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4cdbcc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 22/125 [====>.........................] - ETA: 2:54 - loss: 1.3779 - accuracy: 0.9822WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 625 batches). You may need to use the repeat() function when building your dataset.\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "125/125 [==============================] - 46s 354ms/step - loss: 1.3779 - accuracy: 0.9822 - val_loss: 3.2557 - val_accuracy: 0.9492\n"
     ]
    }
   ],
   "source": [
    "# here we have not giving data to the model we have connected the data generator to the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs = Epochs,\n",
    "    steps_per_epoch = num_train_samples // Batch_size,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = num_validation_samples // Batch_size,\n",
    ")\n",
    "\n",
    "model.save('dog_cat_classifier.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fc28fd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb1ab67",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c7f429",
   "metadata": {},
   "source": [
    "### <font color='blue'> Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ebd1be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 5s 1s/step - loss: 3.2557 - accuracy: 0.9492\n",
      "\n",
      "Accuracy =  94.91525292396545\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(validation_generator)\n",
    "\n",
    "# score give the validation loss and accuracy\n",
    "\n",
    "accuracy = score[1] * 100\n",
    "print('\\nAccuracy = ',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182e825e",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
